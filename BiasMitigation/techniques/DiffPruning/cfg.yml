train_config:
    model_name: "google/bert_uncased_L-2_H-128_A-2" # "bert-base-cased" # 
    batch_size: 128
    structured_diff_pruning: True
    alpha_init: 5
    concrete_lower: -1.5
    concrete_upper: 1.5
    gradient_accumulation_steps: 1
    diff_pruning: True
    num_epochs_finetune: 1
    num_epochs_fixmask: 1
    weight_decay: 0.0
    learning_rate: 5e-5
    learning_rate_alpha: 0.1
    adam_epsilon: 1e-8
    warmup_steps: 0
    sparsity_pen: 1.25e-7
    max_grad_norm: 1.0
    fixmask_pct: 0.01
    logging_step: 5
    output_dir: "checkpoints"
    log_dir: "logs"